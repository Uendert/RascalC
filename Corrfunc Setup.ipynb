{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import Corrfunc \n",
    "from Corrfunc.mocks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Randoms File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corrfunc.io import read_catalog\n",
    "\n",
    "fname = \"random_particles/test_particles_mid.txt\"\n",
    "\n",
    "## Now read in weights and positions:\n",
    "\n",
    "dtype = np.double \n",
    "X, Y, Z, W, J = np.genfromtxt(fname, dtype=dtype, unpack=True, usecols=[0,1,2,3,4])\n",
    "\n",
    "J = np.array(J,dtype=int)\n",
    "N = len(X) # number of particles\n",
    "J_regions = np.unique(J) # jackknire regions in use\n",
    "N_jack = len(J_regions) # number of jackknife regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RR Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "nthreads = 4\n",
    "\n",
    "# Define radial bins\n",
    "nrbins = 10\n",
    "rbins = np.linspace(50.,200.,nrbins+1)\n",
    "\n",
    "# Define mu bins\n",
    "mu_max = 1.;\n",
    "nmu_bins = 6;\n",
    "\n",
    "from Corrfunc.theory.DDsmu import DDsmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT binning:\n",
    "with file('binfile.csv','w+') as writefile:\n",
    "    for i in range(nrbins):\n",
    "        writefile.write(\"%.8f\\t%.8f\\n\" %(rbins[i],rbins[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RR_aA=np.zeros([N_jack,nrbins*nmu_bins]);\n",
    "for i,j in enumerate(J_regions):\n",
    "    filt=np.where(J==j)\n",
    "\n",
    "    # Compute pair counts between jackknife region and entire survey volume\n",
    "    cross_RR=DDsmu(0,nthreads,'binfile.csv',mu_max,nmu_bins,X,Y,Z,weights1=W,weight_type='pair_product',\n",
    "                   X2=X[filt],Y2=Y[filt],Z2=Z[filt],weights2=W[filt],periodic=False,verbose=False)\n",
    "    cross_weights_RR=cross_RR[:]['npairs']*cross_RR[:]['weightavg']\n",
    "    \n",
    "    # Full jackknife RR counts for each bin and jackknife\n",
    "    RR_aA[i]=cross_weights_RR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now save this to file in an appropriate format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_aA=np.zeros_like(RR_aA)\n",
    "RR_a = np.sum(RR_aA,axis=0)\n",
    "for i,j in enumerate(J_regions):\n",
    "    w_aA[i]=RR_aA[i]/RR_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'grid_covariance/weight_files/'\n",
    "import os\n",
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file='jackknife_weights_n%d_m%d_j%d.dat'%(nrbins,nmu_bins,N_jack)\n",
    "with open(filepath+weight_file,\"w+\") as weight_file:\n",
    "    for jackknife_weight in w_aA:\n",
    "        for i in range(len(jackknife_weight)):\n",
    "            weight_file.write(\"%s\\t\" %jackknife_weight[i])\n",
    "        weight_file.write(\"\\n\")\n",
    "RR_a_file = 'binned_pair_counts_n%d_m%d_j%d'%(nrbins,nmu_bins,N_jack)\n",
    "with open(filepath+RR_a_file,\"w+\") as RR_file:\n",
    "    for i in range(len(RR_a)):\n",
    "        RR_file.write(\"%s\\n\" %RR_a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In gridlink_index_particles_double> Running with [nmesh_x, nmesh_y, nmesh_z]  = 16,31,8.  Time taken =   0.100 sec\n",
      "0%.........10%.........20%.........30%.........40%.........50%.........60%.........70%.........80%.........90%....100% done. Time taken = 24.241 secs\n"
     ]
    }
   ],
   "source": [
    "RR = DDsmu(1,nthreads,rbins,mu_max,nmu_bins,X,Y,Z,\n",
    "                 weights1=W,weight_type='pair_product',\n",
    "                 periodic=False,verbose=True,fast_divide_and_NR_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_RR=RR['npairs']*RR['weightavg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Correlation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would need RR, DR and DD counts for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import numpy as np\n",
    ">>> from os.path import dirname, abspath, join as pjoin\n",
    ">>> from Corrfunc.theory.DD import DD\n",
    ">>> from Corrfunc.io import read_catalog\n",
    ">>> \n",
    "\n",
    ">>> # Read the supplied galaxies on a periodic box\n",
    ">>> X, Y, Z = read_catalog()\n",
    ">>> N = len(X)\n",
    ">>> boxsize = 420.0\n",
    ">>> nthreads = 2\n",
    "\n",
    "# Generate randoms on the box\n",
    ">>> rand_N = 3*N\n",
    ">>> rand_X = np.random.uniform(0, boxsize, rand_N)\n",
    ">>> rand_Y = np.random.uniform(0, boxsize, rand_N)\n",
    ">>> rand_Z = np.random.uniform(0, boxsize, rand_N)\n",
    "\n",
    "# Setup the bins\n",
    ">>> nbins = 10\n",
    ">>> bins = np.linspace(0.1, 10.0, nbins + 1) # note that +1 to nbins\n",
    "\n",
    "# Auto pair counts in DD\n",
    ">>> autocorr=1\n",
    ">>> DD_counts = DD(autocorr, nthreads, bins, X, Y, Z,\n",
    "...               periodic=False, verbose=True)\n",
    "\n",
    "# Cross pair counts in DR\n",
    ">>> autocorr=0\n",
    ">>> DR_counts = DD(autocorr, nthreads, bins, X, Y, Z,\n",
    "...               X2=rand_X, Y2=rand_Y, Z2=rand_Z,\n",
    "...               periodic=False, verbose=True)\n",
    "\n",
    "# Auto pairs counts in RR\n",
    ">>> autocorr=1\n",
    ">>> RR_counts = DD(autocorr, nthreads, bins, rand_X, rand_Y, rand_Z,\n",
    "...                periodic=False, verbose=True)\n",
    "\n",
    "# All the pair counts are done, get the correlation function\n",
    ">>> cf = convert_3d_counts_to_cf(N, N, rand_N, rand_N,\n",
    "...                             DD_counts, DR_counts,\n",
    "...                             DR_counts, RR_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
