{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import sys,os\n",
    "sys.path.insert(1,'../../python/')\n",
    "from utils import * # COMAJE utilities\n",
    "file_root='/mnt/store1/oliverphilcox/QPMCovariance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define QPM mock parameter class for matrix read-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPM_Parameters:\n",
    "    \"\"\"Holds covariance matrix parameters for the QPM matrices. These are initially set to default values\"\"\"\n",
    "    def __init__(self,mock_no,mean=False):\n",
    "        self.n=39\n",
    "        self.m=24\n",
    "        self.a=1\n",
    "        self.n_indiv=10\n",
    "        if mean:\n",
    "            self.infile_root=file_root+'HiResMean/'\n",
    "            self.n_indiv=100\n",
    "        else:\n",
    "            self.infile_root=file_root+'Mock_%d/'%mock_no\n",
    "        self.weights_file='/mnt/store1/oliverphilcox/QPM_weights/jackknife_weights_n39_m24_j169.dat'\n",
    "        self.RR_file = '/mnt/store1/oliverphilcox/QPM_weights/binned_pair_counts_n39_m24_j169.dat'\n",
    "        self.r_bins = np.loadtxt('/home/oliverphilcox/COMAJE/python/hybrid_binfile_cut.csv')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load covariance with smooth $\\xi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=QPM_Parameters(0,mean=True)\n",
    "qpm_mean=CovarianceMatrix(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute N_eff and precision matrix:\n",
    "qpm_mean.compute_N_eff();\n",
    "qpm_mean.compute_precision();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load noisy covariance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_cov=[]\n",
    "for i in range(40):\n",
    "    if os.path.exists(file_root+'Mock_%d'%i):\n",
    "        p=QPM_Parameters(i)\n",
    "        try:\n",
    "            noisy_cov.append(CovarianceMatrix(p))            \n",
    "        except OSError:\n",
    "            continue\n",
    "print(\"Read in %d noisy covariance matrices\"%len(noisy_cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare mean determinant per mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_det(cov_matrix):\n",
    "    v=np.linalg.slogdet(cov_matrix.c_tot)[1]/(cov_matrix.n*cov_matrix.m)\n",
    "    return np.exp(v)\n",
    "\n",
    "smooth_mean_det=mean_det(qpm_mean)\n",
    "noisy_mean_dets=[]\n",
    "for i in range(len(noisy_cov)):\n",
    "    noisy_mean_dets.append(mean_det(noisy_cov[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z=plt.hist(noisy_mean_dets,density=True,alpha=0.5,label=r'Noisy $\\xi$')\n",
    "plt.vlines(smooth_mean_det,0,max(x)*1.1,label=r'Smooth $\\xi$');\n",
    "mean,err=np.mean(noisy_mean_dets),np.std(noisy_mean_dets)/np.sqrt(len(noisy_mean_dets))\n",
    "plt.vlines(np.mean(mean),0,max(x)*1.1,linestyles='dotted')\n",
    "yvals=np.linspace(0,max(x)*1.1,100);FS=16\n",
    "plt.ylim(0,max(x)*1.1)\n",
    "plt.fill_betweenx(yvals,np.ones(100)*(mean-err),np.ones(100)*(mean+err),alpha=0.1,color='k')\n",
    "plt.legend(fontsize=FS-2)\n",
    "plt.title('Fine Binning Mean Determininant Per Mode',fontsize=FS-2)\n",
    "plt.ylabel('PDF',fontsize=FS);plt.xlabel(r'$|C_{ab}|^{1/n_\\mathrm{bins}}$',fontsize=FS+3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Diagonals for a noisy and smooth matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt=plotting_tools()\n",
    "fig=pt.plot_diagonal(qpm_mean,name=r'Smooth $\\xi$')\n",
    "pt.plot_diagonal(noisy_cov[1],fig=fig,name=r'Noisy $\\xi$',legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean of 100 xi (top)')\n",
    "pt.plot_reduced_covariance(qpm_mean)\n",
    "print('Single Matrix xi (bottom)')\n",
    "pt.plot_reduced_covariance(noisy_cov[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute KL divergence and $N_\\mathrm{eff}$ estimates\n",
    "Do this for a single noisy mock $\\xi$ and using the smooth $\\xi$ from 100 mocks/\n",
    "\n",
    "First compute for the single high-resolution mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_covs=[]\n",
    "p=QPM_Parameters(1)\n",
    "p.infile_root=file_root+'HiResMock_1/'\n",
    "p.n_indiv=100\n",
    "qpm_1=CovarianceMatrix(p)\n",
    "i_min=5;i_max=p.n_indiv;i_step=3\n",
    "for i in range(i_max):\n",
    "    partial_covs.append(qpm_1.read_all_matrices(root=str(i)))\n",
    "samples_indivs=list(np.arange(i_min,i_max,i_step))\n",
    "N_effs_indivs,KL_div_indivs = [np.zeros(len(samples_indivs)) for _ in range(2)]\n",
    "for j,ii in enumerate(samples_indivs):\n",
    "    print(\"Computing D matrix %d of %d\"%(ii,i_max))\n",
    "    c_tot_mats=partial_covs[:ii]\n",
    "    nn = len(c_tot_mats)\n",
    "    summ=0.\n",
    "    for i in range(nn):\n",
    "        c_excl_i = np.mean(c_tot_mats[:i]+c_tot_mats[i+1:],axis=0)\n",
    "        summ+=np.matmul(np.linalg.inv(c_excl_i),c_tot_mats[i])\n",
    "    D_est = (nn-1.)/nn*(-1.*np.eye(len(c_tot_mats[0]))+1./nn*summ)\n",
    "    slogdetD=np.linalg.slogdet(D_est)\n",
    "    n_bins = len(D_est)\n",
    "    D_value = slogdetD[0]*np.exp(slogdetD[1]/n_bins)\n",
    "    N_effs_indivs[j] = (n_bins+1.)/D_value+1.\n",
    "    KL_div_indivs[j] = KL_divergence(qpm_mean.prec,np.mean(c_tot_mats,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins=len(qpm_mean.prec)\n",
    "N_eff_KL_indiv = [N_bins*(N_bins+1)/(4.*KL) for KL in KL_div_indivs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot true $N_\\mathrm{eff}$ (measuring in-matrix noisy level) against $N_\\mathrm{eff,KL}$ (measuring expected noise if a noisy realization of the smooth $\\xi$ covariance matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(N_effs_indivs/1e5,np.asarray(N_eff_KL_indiv)/1e5,marker='x');\n",
    "plt.ylabel(r'$N_{eff,KL}\\,/\\,10^5$',fontsize=18);plt.xlabel(r'$N_\\mathrm{eff}\\,/\\,10^5$',fontsize=18)\n",
    "plt.title(r'Comparing $N_\\mathrm{eff}$ from Subsample Variance and $D_{KL}$',fontsize=16);\n",
    "#plt.savefig(\"../../plots/N_eff_Subsample.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_from_N_eff=[N_bins*(N_bins+1)/(4.*Ne) for Ne in N_effs_indivs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the expected KL divergence between the noisy and smooth matrix (if the noisy matrix is a realization from the smooth matrix distribution) and the true KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(N_effs_indivs/1e5,np.asarray(D_from_N_eff),marker='x',label='Estimate');\n",
    "plt.scatter(N_effs_indivs/1e5,np.asarray(KL_div_indivs),marker='x',label='True');\n",
    "plt.xlabel(r'$N_\\mathrm{eff}\\,/\\,10^5$',fontsize=18);plt.ylabel(r'$D_{KL}$',fontsize=18);plt.legend(fontsize=14)\n",
    "plt.title(r'KL Divergence Estimates',fontsize=16);\n",
    "#plt.savefig(\"../../plots/D_KL_vs_Estimate.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('NoisySmooth_KLdiv_N_eff_data.npz',N_eff_true=N_effs_indivs,\n",
    "        KL_div_true=KL_div_indivs,N_eff_from_KL=N_eff_KL_indiv,\n",
    "        KL_div_from_N_eff=D_from_N_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
